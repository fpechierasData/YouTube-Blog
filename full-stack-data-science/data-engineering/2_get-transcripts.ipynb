{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb6f999-5cf6-453a-840f-6c2103cf99d5",
   "metadata": {},
   "source": [
    "# Extract Automatic Transcripts from YouTube Videos\n",
    "\n",
    "Code authored by: Shaw Talebi<br>\n",
    "\n",
    "Blog link: https://medium.com/towards-data-science/how-to-build-data-pipelines-for-machine-learning-b97bbef050a5 <br>\n",
    "Video link: https://youtu.be/OnIQrDiTtRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d58eb-315f-418f-bdfc-6022e20a4723",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a56a2a-fff7-4441-b345-1885c24aeafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ac0f2-423a-4493-bdd7-d1698378a9b7",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71753f2a-752c-46f5-a98f-70d3eedf0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(transcript: list) -> str:\n",
    "    \"\"\"\n",
    "        Function to extract text from transcript dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    text_list = [transcript[i]['text'] for i in range(len(transcript))]\n",
    "    return ' '.join(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53671c-1a8c-43b9-a2af-9c21925089a1",
   "metadata": {},
   "source": [
    "### get transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ca35c9-aa8d-40f2-9872-caa52ede4e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────────────┬──────────────────────┬─────────────────────────────────┐\n",
      "│ video_id    ┆ datetime             ┆ title                           │\n",
      "│ ---         ┆ ---                  ┆ ---                             │\n",
      "│ str         ┆ str                  ┆ str                             │\n",
      "╞═════════════╪══════════════════════╪═════════════════════════════════╡\n",
      "│ Ot2c5MKN_-w ┆ 2024-11-20T13:31:14Z ┆ Multimodal AI: LLMs that can s… │\n",
      "│ gUJJB235DVs ┆ 2024-11-18T15:11:07Z ┆ 5 AI Projects You Can Build Th… │\n",
      "│ bAe4qwQGxlI ┆ 2024-10-25T13:18:08Z ┆ I Built an AI App in 4 days...… │\n",
      "│ 4QHg8Ix8WWQ ┆ 2024-10-17T12:50:12Z ┆ Fine-Tuning BERT for Text Clas… │\n",
      "│ tMiQIxSX64c ┆ 2024-10-10T13:50:57Z ┆ 5 AI Projects You Can Build Th… │\n",
      "└─────────────┴──────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_parquet('data/video-ids.parquet')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024d70fe-aa39-464d-93df-cde4129d3cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.94 s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transcript_text_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    # try to extract captions\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(df['video_id'][i])\n",
    "        transcript_text = extract_text(transcript)\n",
    "    # if not available set as n/a\n",
    "    except:\n",
    "        transcript_text = \"n/a\"\n",
    "    \n",
    "    transcript_text_list.append(transcript_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68d0cda-9a05-42e5-a2d3-982ceeb7eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────┬──────────────────────┬──────────────────────────────┬──────────────────────────────┐\n",
      "│ video_id    ┆ datetime             ┆ title                        ┆ transcript                   │\n",
      "│ ---         ┆ ---                  ┆ ---                          ┆ ---                          │\n",
      "│ str         ┆ str                  ┆ str                          ┆ str                          │\n",
      "╞═════════════╪══════════════════════╪══════════════════════════════╪══════════════════════════════╡\n",
      "│ Ot2c5MKN_-w ┆ 2024-11-20T13:31:14Z ┆ Multimodal AI: LLMs that can ┆ multimodal models are        │\n",
      "│             ┆                      ┆ s…                           ┆ capable …                    │\n",
      "│ gUJJB235DVs ┆ 2024-11-18T15:11:07Z ┆ 5 AI Projects You Can Build  ┆ five AI project ideas that   │\n",
      "│             ┆                      ┆ Th…                          ┆ you…                         │\n",
      "│ bAe4qwQGxlI ┆ 2024-10-25T13:18:08Z ┆ I Built an AI App in 4       ┆ I built a web app to         │\n",
      "│             ┆                      ┆ days...…                     ┆ translate…                   │\n",
      "│ 4QHg8Ix8WWQ ┆ 2024-10-17T12:50:12Z ┆ Fine-Tuning BERT for Text    ┆ massive Transformer models   │\n",
      "│             ┆                      ┆ Clas…                        ┆ lik…                         │\n",
      "│ tMiQIxSX64c ┆ 2024-10-10T13:50:57Z ┆ 5 AI Projects You Can Build  ┆ the best way to develop your │\n",
      "│             ┆                      ┆ Th…                          ┆ A…                           │\n",
      "└─────────────┴──────────────────────┴──────────────────────────────┴──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# add transcripts to dataframe\n",
    "df = df.with_columns(pl.Series(name=\"transcript\", values=transcript_text_list))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c68c6f-4617-4636-aff0-20b0d30a9bd7",
   "metadata": {},
   "source": [
    "### write data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5837827f-3ffd-4767-ab0e-06ecdb540f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to file\n",
    "df.write_parquet('data/video-transcripts.parquet')\n",
    "df.write_csv('data/video-transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aafeab-10b0-452e-96c4-b370f3745b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
