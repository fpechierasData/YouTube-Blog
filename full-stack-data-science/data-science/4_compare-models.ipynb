{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a1392b-76ec-45f7-ad25-3a5d103d5b29",
   "metadata": {},
   "source": [
    "# Compare Candidate Search Approaches\n",
    "\n",
    "Code authored by: Shaw Talebi <br>\n",
    "\n",
    "Video link: https://youtu.be/6qCrvlHRhcM <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726e54c-7d53-4dc7-8514-9e74740cb0d0",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667427fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformersNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "                                              0.0/268.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 268.8/268.8 kB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\python_env\\lib\\site-packages (from sentence_transformers) (4.46.2)\n",
      "Requirement already satisfied: tqdm in c:\\python_env\\lib\\site-packages (from sentence_transformers) (4.67.0)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "                                              0.0/203.1 MB ? eta -:--:--\n",
      "                                             2.4/203.1 MB 77.0 MB/s eta 0:00:03\n",
      "     -                                       7.4/203.1 MB 79.0 MB/s eta 0:00:03\n",
      "     --                                     12.3/203.1 MB 93.9 MB/s eta 0:00:03\n",
      "     ---                                    17.2/203.1 MB 93.9 MB/s eta 0:00:02\n",
      "     ---                                   22.0/203.1 MB 108.8 MB/s eta 0:00:02\n",
      "     -----                                  26.9/203.1 MB 93.9 MB/s eta 0:00:02\n",
      "     -----                                  32.0/203.1 MB 93.9 MB/s eta 0:00:02\n",
      "     ------                                36.7/203.1 MB 108.8 MB/s eta 0:00:02\n",
      "     -------                                41.7/203.1 MB 93.0 MB/s eta 0:00:02\n",
      "     --------                              46.7/203.1 MB 108.8 MB/s eta 0:00:02\n",
      "     ---------                             51.5/203.1 MB 108.8 MB/s eta 0:00:02\n",
      "     ----------                            56.7/203.1 MB 108.8 MB/s eta 0:00:02\n",
      "     -----------                           62.0/203.1 MB 108.8 MB/s eta 0:00:02\n",
      "     ------------                          67.1/203.1 MB 131.2 MB/s eta 0:00:02\n",
      "     -------------                         72.3/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     --------------                         77.3/203.1 MB 93.0 MB/s eta 0:00:02\n",
      "     ---------------                       82.5/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     ---------------                       87.7/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     ----------------                      92.9/203.1 MB 110.0 MB/s eta 0:00:02\n",
      "     -----------------                     98.0/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     ------------------                   102.2/203.1 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------                  107.5/203.1 MB 110.0 MB/s eta 0:00:01\n",
      "     -------------------                  112.7/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     --------------------                 118.0/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     ---------------------                123.5/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     ----------------------               128.8/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     -----------------------              134.2/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     ------------------------             139.6/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     -------------------------            145.1/203.1 MB 129.5 MB/s eta 0:00:01\n",
      "     --------------------------           150.7/203.1 MB 131.2 MB/s eta 0:00:01\n",
      "     ---------------------------          155.5/203.1 MB 110.0 MB/s eta 0:00:01\n",
      "     ----------------------------         159.5/203.1 MB 108.8 MB/s eta 0:00:01\n",
      "     -----------------------------         163.4/203.1 MB 93.9 MB/s eta 0:00:01\n",
      "     ------------------------------        167.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     -------------------------------       171.0/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     -------------------------------       175.0/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     --------------------------------      178.9/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ---------------------------------     182.9/203.1 MB 93.9 MB/s eta 0:00:01\n",
      "     ----------------------------------    186.9/203.1 MB 93.9 MB/s eta 0:00:01\n",
      "     ----------------------------------    191.1/203.1 MB 93.9 MB/s eta 0:00:01\n",
      "     -----------------------------------   195.2/203.1 MB 93.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  199.1/203.1 MB 93.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------  203.1/203.1 MB 81.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- 203.1/203.1 MB 14.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in c:\\python_env\\lib\\site-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\python_env\\lib\\site-packages (from sentence_transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\python_env\\lib\\site-packages (from sentence_transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in c:\\python_env\\lib\\site-packages (from sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: filelock in c:\\python_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\flori\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\python_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python_env\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python_env\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "                                              0.0/6.2 MB ? eta -:--:--\n",
      "     ----------------------                   3.5/6.2 MB 113.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.2/6.2 MB 99.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.2/6.2 MB 79.2 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence_transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "                                              0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\flori\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\python_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python_env\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python_env\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python_env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python_env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python_env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python_env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2023.5.7)\n",
      "Installing collected packages: mpmath, sympy, torch, sentence_transformers\n",
      "Successfully installed mpmath-1.3.0 sentence_transformers-3.3.1 sympy-1.13.1 torch-2.5.1\n"
     ]
    }
   ],
   "source": [
    "# pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fabdf5-58b7-4e4f-941f-9398d7be8411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.metrics import DistanceMetric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16fc1e7-bbe7-4a93-b166-4e7a8ea258e2",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b702fc-6389-43d2-b849-8bc6a4076a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (83, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>video_id</th><th>datetime</th><th>title</th><th>transcript</th></tr><tr><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;03x2oYg9oME&quot;</td><td>2024-04-25&nbsp;15:16:00</td><td>&quot;Data&nbsp;Science&nbsp;Project&nbsp;Managemen…</td><td>&quot;this&nbsp;video&nbsp;is&nbsp;part&nbsp;of&nbsp;a&nbsp;larger…</td></tr><tr><td>&quot;O5i_mMUM94c&quot;</td><td>2024-04-19&nbsp;14:05:54</td><td>&quot;How&nbsp;I’d&nbsp;learned&nbsp;#datascience&nbsp;(…</td><td>&quot;here&#x27;s&nbsp;how&nbsp;I&#x27;d&nbsp;learn&nbsp;data&nbsp;scie…</td></tr><tr><td>&quot;xm9devSQEqU&quot;</td><td>2024-04-18&nbsp;15:59:02</td><td>&quot;4&nbsp;Skills&nbsp;You&nbsp;Need&nbsp;to&nbsp;Be&nbsp;a&nbsp;Full…</td><td>&quot;although&nbsp;it&nbsp;is&nbsp;common&nbsp;to&nbsp;deleg…</td></tr><tr><td>&quot;Z6CmuVEi7QY&quot;</td><td>2024-04-11&nbsp;10:00:27</td><td>&quot;How&nbsp;I&#x27;d&nbsp;Learn&nbsp;Data&nbsp;Science&nbsp;(if…</td><td>&quot;when&nbsp;I&nbsp;was&nbsp;first&nbsp;learning&nbsp;data…</td></tr><tr><td>&quot;INlCLmWlojY&quot;</td><td>2024-04-04&nbsp;18:45:00</td><td>&quot;I&nbsp;Was&nbsp;Wrong&nbsp;About&nbsp;AI&nbsp;Consultin…</td><td>&quot;last&nbsp;year&nbsp;I&nbsp;quit&nbsp;my&nbsp;corporate&nbsp;…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;MX7ymkYGiZ0&quot;</td><td>2020-12-21&nbsp;00:24:45</td><td>&quot;The&nbsp;Wavelet&nbsp;Transform&nbsp;|&nbsp;Introd…</td><td>&quot;hey&nbsp;guys&nbsp;welcome&nbsp;back&nbsp;in&nbsp;this&nbsp;…</td></tr><tr><td>&quot;rPUytg38b6Q&quot;</td><td>2020-12-04&nbsp;01:10:36</td><td>&quot;The&nbsp;Fast&nbsp;Fourier&nbsp;Transform&nbsp;|&nbsp;H…</td><td>&quot;hey&nbsp;guys&nbsp;welcome&nbsp;back&nbsp;in&nbsp;this&nbsp;…</td></tr><tr><td>&quot;mj86XmfOniY&quot;</td><td>2020-11-15&nbsp;20:41:53</td><td>&quot;Time&nbsp;Series,&nbsp;Signals,&nbsp;&amp;&nbsp;the&nbsp;Fo…</td><td>&quot;yeah&nbsp;hey&nbsp;guys&nbsp;welcome&nbsp;my&nbsp;name&nbsp;…</td></tr><tr><td>&quot;Gwz4zXPeP_Q&quot;</td><td>2020-11-12&nbsp;22:58:00</td><td>&quot;biometricDahboard3&nbsp;DEMO&quot;</td><td>&quot;n/a&quot;</td></tr><tr><td>&quot;lciC1s4FO0g&quot;</td><td>2020-09-23&nbsp;13:02:57</td><td>&quot;biometricDashboard2&nbsp;DEMO&quot;</td><td>&quot;n/a&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (83, 4)\n",
       "┌─────────────┬─────────────────────┬──────────────────────────────────┬───────────────────────────┐\n",
       "│ video_id    ┆ datetime            ┆ title                            ┆ transcript                │\n",
       "│ ---         ┆ ---                 ┆ ---                              ┆ ---                       │\n",
       "│ str         ┆ datetime[μs]        ┆ str                              ┆ str                       │\n",
       "╞═════════════╪═════════════════════╪══════════════════════════════════╪═══════════════════════════╡\n",
       "│ 03x2oYg9oME ┆ 2024-04-25 15:16:00 ┆ Data Science Project Managemen…  ┆ this video is part of a   │\n",
       "│             ┆                     ┆                                  ┆ larger…                   │\n",
       "│ O5i_mMUM94c ┆ 2024-04-19 14:05:54 ┆ How I’d learned #datascience (…  ┆ here's how I'd learn data │\n",
       "│             ┆                     ┆                                  ┆ scie…                     │\n",
       "│ xm9devSQEqU ┆ 2024-04-18 15:59:02 ┆ 4 Skills You Need to Be a Full…  ┆ although it is common to  │\n",
       "│             ┆                     ┆                                  ┆ deleg…                    │\n",
       "│ Z6CmuVEi7QY ┆ 2024-04-11 10:00:27 ┆ How I'd Learn Data Science (if…  ┆ when I was first learning │\n",
       "│             ┆                     ┆                                  ┆ data…                     │\n",
       "│ INlCLmWlojY ┆ 2024-04-04 18:45:00 ┆ I Was Wrong About AI Consultin…  ┆ last year I quit my       │\n",
       "│             ┆                     ┆                                  ┆ corporate …               │\n",
       "│ …           ┆ …                   ┆ …                                ┆ …                         │\n",
       "│ MX7ymkYGiZ0 ┆ 2020-12-21 00:24:45 ┆ The Wavelet Transform | Introd…  ┆ hey guys welcome back in  │\n",
       "│             ┆                     ┆                                  ┆ this …                    │\n",
       "│ rPUytg38b6Q ┆ 2020-12-04 01:10:36 ┆ The Fast Fourier Transform | H…  ┆ hey guys welcome back in  │\n",
       "│             ┆                     ┆                                  ┆ this …                    │\n",
       "│ mj86XmfOniY ┆ 2020-11-15 20:41:53 ┆ Time Series, Signals, & the Fo…  ┆ yeah hey guys welcome my  │\n",
       "│             ┆                     ┆                                  ┆ name …                    │\n",
       "│ Gwz4zXPeP_Q ┆ 2020-11-12 22:58:00 ┆ biometricDahboard3 DEMO          ┆ n/a                       │\n",
       "│ lciC1s4FO0g ┆ 2020-09-23 13:02:57 ┆ biometricDashboard2 DEMO         ┆ n/a                       │\n",
       "└─────────────┴─────────────────────┴──────────────────────────────────┴───────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet('data/video-transcripts.parquet')\n",
    "df_eval = pl.read_csv('data/eval-raw.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5435a1-1f74-47b3-bddd-929f5c4908fe",
   "metadata": {},
   "source": [
    "### embed titles and transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0fb5ddb-5278-42a4-a6cf-f6161e59d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \"parameters\"\n",
    "column_to_embed_list = ['title', 'transcript']\n",
    "model_name_list = [\"all-MiniLM-L6-v2\", \"multi-qa-distilbert-cos-v1\", \"multi-qa-mpnet-base-dot-v1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad995bfd-dea8-4514-8392-00f941496edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2_title\n",
      "CPU times: total: 1.48 s\n",
      "Wall time: 190 ms\n",
      "\n",
      "all-MiniLM-L6-v2_transcript\n",
      "CPU times: total: 12.5 s\n",
      "Wall time: 1.23 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1_title\n",
      "CPU times: total: 3.23 s\n",
      "Wall time: 374 ms\n",
      "\n",
      "multi-qa-distilbert-cos-v1_transcript\n",
      "CPU times: total: 1min 23s\n",
      "Wall time: 7.43 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_title\n",
      "CPU times: total: 6.56 s\n",
      "Wall time: 763 ms\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_transcript\n",
      "CPU times: total: 3min 41s\n",
      "Wall time: 20.1 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings for each combination of column and model\n",
    "\n",
    "# initialize dict to keep track of all text embeddings\n",
    "text_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    #define embedding model\n",
    "    model = SentenceTransformer(model_name) \n",
    "\n",
    "    for column_name in column_to_embed_list:\n",
    "\n",
    "        # define text embedding identifier\n",
    "        key_name = model_name + \"_\" + column_name\n",
    "        print(key_name)\n",
    "\n",
    "        # generate embeddings for text under column_name\n",
    "        %time embedding_arr = model.encode(df[column_name].to_list())\n",
    "        print('')\n",
    "\n",
    "        # append embeddings to dict\n",
    "        text_embedding_dict[key_name] = embedding_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c697f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a2886-4c1f-459b-8d74-4b2a60cc5ce2",
   "metadata": {},
   "source": [
    "### embed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2cc13c-a6dc-4354-938c-7383140b1a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n",
      "CPU times: total: 1.3 s\n",
      "Wall time: 165 ms\n",
      "\n",
      "multi-qa-distilbert-cos-v1\n",
      "CPU times: total: 4.16 s\n",
      "Wall time: 460 ms\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1\n",
      "CPU times: total: 7.92 s\n",
      "Wall time: 916 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    #define embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(model_name)\n",
    "\n",
    "    # embed query text\n",
    "    %time embedding_arr = model.encode(df_eval['query'].to_list())\n",
    "    print('')\n",
    "\n",
    "    # append embedding to dict\n",
    "    query_embedding_dict[model_name] = embedding_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe42a5-63d0-4ac9-b443-7bec945af178",
   "metadata": {},
   "source": [
    "### Evaluate search methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8d5792-d3e5-4b3c-b467-1e323684be18",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def returnVideoID_index(df: pl.dataframe.frame.DataFrame, df_eval: pl.dataframe.frame.DataFrame, query_n: int) -> int:\n",
    "    \"\"\"\n",
    "        Function to return the index of a dataframe corresponding to the nth row in evaluation dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    return [i for i in range(len(df)) if df['video_id'][i]==df_eval['video_id'][query_n]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a67a04-ff18-4017-a2dc-1b0779d02519",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def evalTrueRankings(dist_arr_isorted: np.ndarray, df: pl.dataframe.frame.DataFrame, df_eval: pl.dataframe.frame.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Function to return \"true\" video ID rankings for each evaluation query\n",
    "    \"\"\"\n",
    "    \n",
    "    # intialize array to store rankings of \"correct\" search result\n",
    "    true_rank_arr = np.empty((1, dist_arr_isorted.shape[1]))\n",
    "    \n",
    "    # evaluate ranking of correct result for each query\n",
    "    for query_n in range(dist_arr_isorted.shape[1]):\n",
    "    \n",
    "        # return \"true\" video ID's in df\n",
    "        video_id_idx = returnVideoID_index(df, df_eval, query_n)\n",
    "        \n",
    "        # evaluate the ranking of the \"true\" video ID\n",
    "        true_rank = np.argwhere(dist_arr_isorted[:,query_n]==video_id_idx)[0][0]\n",
    "        \n",
    "        # store the \"true\" video ID's ranking in array\n",
    "        true_rank_arr[0,query_n] = true_rank\n",
    "\n",
    "    return true_rank_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d5fd16-b4cc-48d7-bd47-e948fdc94906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize distance metrics to experiment\n",
    "dist_name_list = ['euclidean', 'manhattan', 'chebyshev']\n",
    "sim_name_list = ['cos_sim', 'dot_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f4e57f0-d4bd-48b9-a8c7-4633a2a8dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate all possible combinations of model, columns to embed, and distance metrics\n",
    "\n",
    "# initialize list to store results\n",
    "eval_results = []\n",
    "\n",
    "# loop through all models\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    # generate query embedding\n",
    "    query_embedding = query_embedding_dict[model_name]\n",
    "    \n",
    "    # loop through text columns\n",
    "    for column_name in column_to_embed_list:\n",
    "\n",
    "        # generate column embedding\n",
    "        embedding_arr = text_embedding_dict[model_name+'_'+column_name]\n",
    "\n",
    "        # loop through distance metrics\n",
    "        for dist_name in dist_name_list:\n",
    "\n",
    "            # compute distance between video text and query\n",
    "            dist = DistanceMetric.get_metric(dist_name)\n",
    "            dist_arr = dist.pairwise(embedding_arr, query_embedding)\n",
    "\n",
    "            # sort indexes of distance array\n",
    "            dist_arr_isorted = np.argsort(dist_arr, axis=0)\n",
    "\n",
    "            # define label for search method\n",
    "            method_name = \"_\".join([model_name, column_name, dist_name])\n",
    "\n",
    "            # evaluate the ranking of the ground truth\n",
    "            true_rank_arr = evalTrueRankings(dist_arr_isorted, df, df_eval)\n",
    "\n",
    "            # store results\n",
    "            eval_list = [method_name] + true_rank_arr.tolist()[0]\n",
    "            eval_results.append(eval_list)\n",
    "\n",
    "        # loop through sbert similarity scores\n",
    "        for sim_name in sim_name_list:\n",
    "            # apply similarity score from sbert\n",
    "            cmd = \"dist_arr = -util.\" + sim_name + \"(embedding_arr, query_embedding)\"\n",
    "            exec(cmd)\n",
    "    \n",
    "            # sort indexes of distance array (notice minus sign in front of cosine similarity)\n",
    "            dist_arr_isorted = np.argsort(dist_arr, axis=0)\n",
    "    \n",
    "            # define label for search method\n",
    "            method_name = \"_\".join([model_name, column_name, sim_name.replace(\"_\",\"-\")])\n",
    "    \n",
    "            # evaluate the ranking of the ground truth\n",
    "            true_rank_arr = evalTrueRankings(dist_arr_isorted, df, df_eval)\n",
    "    \n",
    "            # store results\n",
    "            eval_list = [method_name] + true_rank_arr.tolist()[0]\n",
    "            eval_results.append(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88321681-0547-4855-abb6-5537573155e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dist_arr = -util.dot_score(embedding_arr, query_embedding)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc50dce4-0cbf-4d56-bb98-d3704c8e668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rankings for title + transcripts embedding\n",
    "for model_name in model_name_list:\n",
    "    \n",
    "    # generate embeddings\n",
    "    embedding_arr1 = text_embedding_dict[model_name+'_title']\n",
    "    embedding_arr2 = text_embedding_dict[model_name+'_transcript']\n",
    "    query_embedding = query_embedding_dict[model_name]\n",
    "\n",
    "    for dist_name in dist_name_list:\n",
    "\n",
    "        # compute distance between video text and query\n",
    "        dist = DistanceMetric.get_metric(dist_name)\n",
    "        dist_arr = dist.pairwise(embedding_arr1, query_embedding) + dist.pairwise(embedding_arr2, query_embedding)\n",
    "\n",
    "        # sort indexes of distance array\n",
    "        dist_arr_isorted = np.argsort(dist_arr, axis=0)\n",
    "\n",
    "         # define label for search method\n",
    "        method_name = \"_\".join([model_name, \"title-transcript\", dist_name])\n",
    "\n",
    "        # evaluate the ranking of the ground truth\n",
    "        true_rank_arr = evalTrueRankings(dist_arr_isorted, df, df_eval)\n",
    "\n",
    "        # store results\n",
    "        eval_list = [method_name] + true_rank_arr.tolist()[0]\n",
    "        eval_results.append(eval_list)\n",
    "\n",
    "    # loop through sbert similarity scores\n",
    "    for sim_name in sim_name_list:\n",
    "        # apply similarity score from sbert\n",
    "        cmd = \"dist_arr = -util.\" + sim_name + \"(embedding_arr1, query_embedding) - util.\"+ sim_name + \"(embedding_arr2, query_embedding)\"\n",
    "        exec(cmd)\n",
    "\n",
    "        # sort indexes of distance array (notice minus sign in front of cosine similarity)\n",
    "        dist_arr_isorted = np.argsort(dist_arr, axis=0)\n",
    "\n",
    "        # define label for search method\n",
    "        method_name = \"_\".join([model_name, \"title-transcript\", sim_name.replace(\"_\",\"-\")])\n",
    "\n",
    "        # evaluate the ranking of the ground truth\n",
    "        true_rank_arr = evalTrueRankings(dist_arr_isorted, df, df_eval)\n",
    "\n",
    "        # store results\n",
    "        eval_list = [method_name] + true_rank_arr.tolist()[0]\n",
    "        eval_results.append(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec5ff78-7761-4048-90ed-71f93d77ba8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac91899c-b54b-4751-b929-5d533db4009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_17812\\3887212411.py:7: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  df_results = pl.DataFrame(eval_results, schema=schema_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 65)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>method_name</th><th>rank_query-0</th><th>rank_query-1</th><th>rank_query-2</th><th>rank_query-3</th><th>rank_query-4</th><th>rank_query-5</th><th>rank_query-6</th><th>rank_query-7</th><th>rank_query-8</th><th>rank_query-9</th><th>rank_query-10</th><th>rank_query-11</th><th>rank_query-12</th><th>rank_query-13</th><th>rank_query-14</th><th>rank_query-15</th><th>rank_query-16</th><th>rank_query-17</th><th>rank_query-18</th><th>rank_query-19</th><th>rank_query-20</th><th>rank_query-21</th><th>rank_query-22</th><th>rank_query-23</th><th>rank_query-24</th><th>rank_query-25</th><th>rank_query-26</th><th>rank_query-27</th><th>rank_query-28</th><th>rank_query-29</th><th>rank_query-30</th><th>rank_query-31</th><th>rank_query-32</th><th>rank_query-33</th><th>rank_query-34</th><th>rank_query-35</th><th>rank_query-36</th><th>rank_query-37</th><th>rank_query-38</th><th>rank_query-39</th><th>rank_query-40</th><th>rank_query-41</th><th>rank_query-42</th><th>rank_query-43</th><th>rank_query-44</th><th>rank_query-45</th><th>rank_query-46</th><th>rank_query-47</th><th>rank_query-48</th><th>rank_query-49</th><th>rank_query-50</th><th>rank_query-51</th><th>rank_query-52</th><th>rank_query-53</th><th>rank_query-54</th><th>rank_query-55</th><th>rank_query-56</th><th>rank_query-57</th><th>rank_query-58</th><th>rank_query-59</th><th>rank_query-60</th><th>rank_query-61</th><th>rank_query-62</th><th>rank_query-63</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;all-MiniLM-L6-v2_title_euclide…</td><td>0.0</td><td>0.0</td><td>16.0</td><td>0.0</td><td>7.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>8.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>6.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>9.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;all-MiniLM-L6-v2_title_manhatt…</td><td>0.0</td><td>0.0</td><td>9.0</td><td>0.0</td><td>7.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>7.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>10.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;all-MiniLM-L6-v2_title_chebysh…</td><td>0.0</td><td>2.0</td><td>46.0</td><td>0.0</td><td>60.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>3.0</td><td>0.0</td><td>30.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>57.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>24.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>8.0</td><td>6.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>43.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>6.0</td><td>8.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>5.0</td><td>1.0</td><td>70.0</td><td>11.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;all-MiniLM-L6-v2_title_cos-sim&quot;</td><td>0.0</td><td>0.0</td><td>16.0</td><td>0.0</td><td>7.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>8.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>6.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>9.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;all-MiniLM-L6-v2_title_dot-sco…</td><td>0.0</td><td>0.0</td><td>16.0</td><td>0.0</td><td>7.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>8.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>6.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>9.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 65)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ method_na ┆ rank_quer ┆ rank_quer ┆ rank_quer ┆ … ┆ rank_quer ┆ rank_quer ┆ rank_quer ┆ rank_que │\n",
       "│ me        ┆ y-0       ┆ y-1       ┆ y-2       ┆   ┆ y-60      ┆ y-61      ┆ y-62      ┆ ry-63    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ all-MiniL ┆ 0.0       ┆ 0.0       ┆ 16.0      ┆ … ┆ 1.0       ┆ 0.0       ┆ 1.0       ┆ 0.0      │\n",
       "│ M-L6-v2_t ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ itle_eucl ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ide…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ all-MiniL ┆ 0.0       ┆ 0.0       ┆ 9.0       ┆ … ┆ 1.0       ┆ 0.0       ┆ 1.0       ┆ 0.0      │\n",
       "│ M-L6-v2_t ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ itle_manh ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ att…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ all-MiniL ┆ 0.0       ┆ 2.0       ┆ 46.0      ┆ … ┆ 1.0       ┆ 1.0       ┆ 1.0       ┆ 0.0      │\n",
       "│ M-L6-v2_t ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ itle_cheb ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ysh…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ all-MiniL ┆ 0.0       ┆ 0.0       ┆ 16.0      ┆ … ┆ 1.0       ┆ 0.0       ┆ 1.0       ┆ 0.0      │\n",
       "│ M-L6-v2_t ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ itle_cos- ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ sim       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ all-MiniL ┆ 0.0       ┆ 0.0       ┆ 16.0      ┆ … ┆ 1.0       ┆ 0.0       ┆ 1.0       ┆ 0.0      │\n",
       "│ M-L6-v2_t ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ itle_dot- ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ sco…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define schema for results dataframe\n",
    "schema_dict = {'method_name':str}\n",
    "for i in range(len(eval_results[0])-1):\n",
    "    schema_dict['rank_query-'+str(i)] = float\n",
    "\n",
    "# store results in dataframe\n",
    "df_results = pl.DataFrame(eval_results, schema=schema_dict)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdfedef4-64fb-4852-a5e6-2047c4ee654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean rankings of ground truth search result\n",
    "df_results = df_results.with_columns(new_col=pl.mean_horizontal(df_results.columns[1:])).rename({\"new_col\": \"rank_query-mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "405ce9c5-6347-4995-adbe-4e8cf92727cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of ground truth results which appear in top 3\n",
    "for i in [1,3]:\n",
    "    df_results = df_results.with_columns(new_col=pl.sum_horizontal(df_results[:,1:-1]<i)).rename({\"new_col\": \"num_in_top-\"+str(i)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb87b41-52fa-4e89-bb98-2e7011665a27",
   "metadata": {},
   "source": [
    "### Look at top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dac1368-fd3d-4ac1-90b8-d2429e2aadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = df_results[['method_name', \"rank_query-mean\", \"num_in_top-1\", \"num_in_top-3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "332a9783-8fe7-40b8-929c-a2e973e18207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────────────────────────┬─────────────────┬──────────────┬──────────────┐\n",
      "│ method_name                     ┆ rank_query-mean ┆ num_in_top-1 ┆ num_in_top-3 │\n",
      "│ ---                             ┆ ---             ┆ ---          ┆ ---          │\n",
      "│ str                             ┆ f64             ┆ u32          ┆ u32          │\n",
      "╞═════════════════════════════════╪═════════════════╪══════════════╪══════════════╡\n",
      "│ all-MiniLM-L6-v2_title-transcr… ┆ 0.875           ┆ 41           ┆ 60           │\n",
      "│ all-MiniLM-L6-v2_title_manhatt… ┆ 0.921875        ┆ 44           ┆ 58           │\n",
      "│ all-MiniLM-L6-v2_title-transcr… ┆ 0.96875         ┆ 41           ┆ 61           │\n",
      "│ all-MiniLM-L6-v2_title-transcr… ┆ 0.984375        ┆ 41           ┆ 60           │\n",
      "│ all-MiniLM-L6-v2_title-transcr… ┆ 0.984375        ┆ 41           ┆ 60           │\n",
      "└─────────────────────────────────┴─────────────────┴──────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df_summary.sort('rank_query-mean').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bd138a2-cd56-48c6-bb5b-ed7cd159dae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all-MiniLM-L6-v2_title-transcript_manhattan'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.sort('rank_query-mean').head()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae0ba9ed-d199-41b1-ad2b-f65604ac1767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────────────────────────┬─────────────────┬──────────────┬──────────────┐\n",
      "│ method_name                     ┆ rank_query-mean ┆ num_in_top-1 ┆ num_in_top-3 │\n",
      "│ ---                             ┆ ---             ┆ ---          ┆ ---          │\n",
      "│ str                             ┆ f64             ┆ u32          ┆ u32          │\n",
      "╞═════════════════════════════════╪═════════════════╪══════════════╪══════════════╡\n",
      "│ all-MiniLM-L6-v2_title_euclide… ┆ 1.09375         ┆ 45           ┆ 57           │\n",
      "│ all-MiniLM-L6-v2_title_cos-sim  ┆ 1.09375         ┆ 45           ┆ 57           │\n",
      "│ all-MiniLM-L6-v2_title_dot-sco… ┆ 1.09375         ┆ 45           ┆ 57           │\n",
      "│ multi-qa-mpnet-base-dot-v1_tit… ┆ 1.8125          ┆ 45           ┆ 57           │\n",
      "│ all-MiniLM-L6-v2_title_manhatt… ┆ 0.921875        ┆ 44           ┆ 58           │\n",
      "└─────────────────────────────────┴─────────────────┴──────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df_summary.sort(\"num_in_top-1\", descending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab8c75c9-967b-47f1-92f7-fad4297b73b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all-MiniLM-L6-v2_title_euclidean'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.sort(\"num_in_top-1\", descending=True).head()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2761e67b-97cf-4552-9820-442ef440ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────────────────────────┬─────────────────┬──────────────┬──────────────┐\n",
      "│ method_name                     ┆ rank_query-mean ┆ num_in_top-1 ┆ num_in_top-3 │\n",
      "│ ---                             ┆ ---             ┆ ---          ┆ ---          │\n",
      "│ str                             ┆ f64             ┆ u32          ┆ u32          │\n",
      "╞═════════════════════════════════╪═════════════════╪══════════════╪══════════════╡\n",
      "│ all-MiniLM-L6-v2_title-transcr… ┆ 0.96875         ┆ 41           ┆ 61           │\n",
      "│ multi-qa-distilbert-cos-v1_tit… ┆ 1.59375         ┆ 43           ┆ 61           │\n",
      "│ multi-qa-distilbert-cos-v1_tit… ┆ 1.625           ┆ 42           ┆ 61           │\n",
      "│ multi-qa-distilbert-cos-v1_tit… ┆ 1.625           ┆ 42           ┆ 61           │\n",
      "│ multi-qa-distilbert-cos-v1_tit… ┆ 1.765625        ┆ 44           ┆ 60           │\n",
      "└─────────────────────────────────┴─────────────────┴──────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df_summary.sort(\"num_in_top-3\", descending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5c5d5d2-fcd5-4b2f-bc74-c875673ee8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all-MiniLM-L6-v2_title-transcript_euclidean'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.sort(\"num_in_top-3\", descending=True).head()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff4e8924-d53c-42a6-88f5-3bd5f726174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2_title-transcript_euclidean\n",
      "multi-qa-distilbert-cos-v1_title-transcript_euclidean\n",
      "multi-qa-distilbert-cos-v1_title-transcript_cos-sim\n",
      "multi-qa-distilbert-cos-v1_title-transcript_dot-score\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(df_summary.sort(\"num_in_top-3\", descending=True)['method_name'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294c889-6ef6-48c7-bb20-05a15a87b58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
